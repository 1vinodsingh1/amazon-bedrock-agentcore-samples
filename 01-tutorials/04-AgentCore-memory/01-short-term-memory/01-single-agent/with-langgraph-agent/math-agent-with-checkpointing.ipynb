{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "8208f7d6-391d-4054-9e67-ac0f85878dcd",
            "metadata": {},
            "source": [
                "# LangGraph with AgentCore Memory Checkpointer (Short term memory)\n",
                "\n",
                "## Introduction\n",
                "This notebook demonstrates how to integrate Amazon Bedrock AgentCore Memory capabilities with LangGraph using the **AgentCoreMemorySaver** checkpointer. We'll focus on **short-term memory** persistence across conversation turns - allowing an agent to maintain running context and build upon previous calculations through automatic state checkpointing.\n",
                "\n",
                "## Tutorial Details\n",
                "\n",
                "| Information         | Details                                                                          |\n",
                "|:--------------------|:---------------------------------------------------------------------------------|\n",
                "| Tutorial type       | Short Term Conversational                                                        |\n",
                "| Agent usecase       | Multi-step Math Calculations                                                     |\n",
                "| Agentic Framework   | Langgraph                                                                        |\n",
                "| LLM model           | Anthropic Claude Sonnet 3.7                                                      |\n",
                "| Tutorial components | AgentCore Short-term Memory, Langgraph Checkpointer, Math Tools                |\n",
                "| Example complexity  | Beginner                                                                         |\n",
                "\n",
                "You'll learn to:\n",
                "- Create a memory checkpointer with AgentCore Memory for automatic state persistence\n",
                "- Use LangGraph's built-in checkpointing system with AgentCore Memory backend\n",
                "- Maintain conversation context across multiple interactions\n",
                "- Inspect and manage conversation state and history\n",
                "\n",
                "### Scenario Context\n",
                "\n",
                "In this example, we'll create a \"**Math Agent**\" that can perform multi-step mathematical calculations. Unlike simple one-off interactions, this agent uses AgentCore Memory's checkpointing capabilities to maintain running context, allowing it to build upon previous calculations and remember the conversation flow across multiple turns.\n",
                "\n",
                "## Architecture\n",
                "<div style=\"text-align:left\">\n",
                "    <img src=\"images/architecture.png\" width=\"65%\" />\n",
                "</div>\n",
                "\n",
                "## Prerequisites\n",
                "\n",
                "- Python 3.10+\n",
                "- AWS account with appropriate permissions\n",
                "- AWS IAM role with appropriate permissions for AgentCore Memory\n",
                "- Access to Amazon Bedrock models\n",
                "\n",
                "### How the Integration Works\n",
                "\n",
                "The integration between LangGraph and AgentCore Memory involves:\n",
                "\n",
                "1. Using AgentCore Memory as a checkpointer backend for LangGraph state persistence\n",
                "2. Automatic saving and loading of conversation state at each step\n",
                "3. Support for multiple concurrent sessions and actors\n",
                "\n",
                "This approach provides seamless state management without requiring manual memory operations, creating a more maintainable and scalable agent architecture."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e6acbf4e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install necessary libraries\n",
                "!pip install -qr requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8eff8706-6715-4981-983b-934561ee0a19",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import LangGraph and LangChain components\n",
                "from langchain.chat_models import init_chat_model\n",
                "from langchain.tools import tool\n",
                "from langgraph.prebuilt import create_react_agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fc12fd92-b84a-4d2f-b96d-83d3da08bf70",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the AgentCoreMemorySaver that we will use as a checkpointer\n",
                "import os\n",
                "import logging\n",
                "\n",
                "from langgraph_checkpoint_aws import AgentCoreMemorySaver\n",
                "from bedrock_agentcore.memory import MemoryClient\n",
                "\n",
                "region = os.getenv('AWS_REGION', 'us-west-2')\n",
                "logging.getLogger(\"math-agent\").setLevel(logging.DEBUG)\n",
                "\n",
                "# Create or get the memory resource\n",
                "memory_name = \"MathLanggraphAgent\"\n",
                "client = MemoryClient(region_name=region)\n",
                "memory = client.create_or_get_memory(name=memory_name)\n",
                "memory_id = memory['id'] # Keep this memory ID for later use"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "51d91a14-541c-426c-a52c-5fdcf29f8953",
            "metadata": {},
            "source": [
                "### AgentCore Memory Configuration\n",
                "\n",
                "Now let's configure our AgentCore Memory checkpointer and initialize the LLM:\n",
                "\n",
                "- `memory_id` corresponds to our AgentCore Memory resource where checkpoints will be stored\n",
                "- `region` specifies the AWS region for our resources\n",
                "- `MODEL_ID` defines the Bedrock model that will power our LangGraph agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "226d094c-a05d-4f88-851d-cc42ff63ef11",
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
                "\n",
                "# Initialize checkpointer for state persistence\n",
                "checkpointer = AgentCoreMemorySaver(memory_id, region_name=region)\n",
                "\n",
                "# Initialize LLM\n",
                "llm = init_chat_model(MODEL_ID, model_provider=\"bedrock_converse\", region_name=region)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c56c77aa-4b19-49a5-af3c-db2b4798384b",
            "metadata": {},
            "source": [
                "### Mathematical Tools\n",
                "\n",
                "Let's define the mathematical tools our agent will use. For this demonstration, we'll provide two simple operations:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dd81ba1c-3fb8-474c-ae40-0ee7c62ca234",
            "metadata": {},
            "outputs": [],
            "source": [
                "@tool\n",
                "def add(a: int, b: int):\n",
                "    \"\"\"Add two integers and return the result\"\"\"\n",
                "    return a + b\n",
                "\n",
                "\n",
                "@tool\n",
                "def multiply(a: int, b: int):\n",
                "    \"\"\"Multiply two integers and return the result\"\"\"\n",
                "    return a * b\n",
                "\n",
                "\n",
                "tools = [add, multiply]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "651b6e3f-8b41-4c07-8a32-680666b2661e",
            "metadata": {},
            "source": [
                "### LangGraph Agent Implementation\n",
                "\n",
                "Now let's create our agent using LangGraph's `create_react_agent` builder with our AgentCore Memory checkpointer:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a116a57f",
            "metadata": {},
            "outputs": [],
            "source": [
                "graph = create_react_agent(\n",
                "    model=llm,\n",
                "    tools=tools,\n",
                "    prompt=\"You are a helpful assistant\",\n",
                "    checkpointer=checkpointer,\n",
                ")\n",
                "\n",
                "graph"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b6cbbb3a-f85c-42f5-bbfb-40f5f6b8b48c",
            "metadata": {},
            "source": [
                "## Step 4: Run the LangGraph Agent\n",
                "We can now run the agent with our AgentCore Memory checkpointer integration.\n",
                "\n",
                "### Configuration Setup\n",
                "In LangGraph, config is a `RuntimeConfig` that contains attributes that are necessary at invocation time, for example user IDs or session IDs. You can read additional documentation here: [https://langchain-ai.github.io/langgraphjs/how-tos/configuration/](https://langchain-ai.github.io/langgraphjs/how-tos/configuration/)\n",
                "\n",
                "For the AgentCore Memory checkpointer (`AgentCoreMemorySaver`), we NEED to specify:\n",
                "- `thread_id`: Maps to AgentCore session_id (unique conversation thread)\n",
                "- `actor_id`: Maps to AgentCore actor_id (user, agent, or any other identifier)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "859fee36-1eff-4713-9c3b-387b702c0301",
            "metadata": {},
            "outputs": [],
            "source": [
                "config = {\n",
                "    \"configurable\": {\n",
                "        \"thread_id\": \"session-1\", # REQUIRED: This maps to Bedrock AgentCore session_id under the hood\n",
                "        \"actor_id\": \"react-agent-1\", # REQUIRED: This maps to Bedrock AgentCore actor_id under the hood\n",
                "    }\n",
                "}\n",
                "\n",
                "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What is 1337 times 515321? Then add 412 and return the value to me.\"}]}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "96044de0-2d32-4811-ac30-43f4416f4303",
            "metadata": {},
            "source": [
                "#### Congratulations! Your Agent is ready!!\n",
                "\n",
                "### Let's test the Agent\n",
                "\n",
                "Let's run our first calculation to see the agent in action:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2bc4869-58cd-4914-9a7a-8d39ecd16226",
            "metadata": {},
            "outputs": [],
            "source": [
                "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
                "    print(chunk)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f0d28db8-c9cc-4fa1-922d-89476e9f71c5",
            "metadata": {},
            "source": [
                "### Inspecting Agent State\n",
                "\n",
                "Let's examine the current conversation state stored in AgentCore Memory. The checkpointer automatically saves and retrieves state for our actor and session:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "60042ec5-cd64-48f3-bd7d-cb7ca9e21b39",
            "metadata": {},
            "outputs": [],
            "source": [
                "for message in graph.get_state(config).values.get(\"messages\"):\n",
                "    print(f\"{message.type}: {message.text()}\")\n",
                "    print(\"=========================================\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3aa0c9bd-6fb6-467d-b51a-84696238b4fa",
            "metadata": {},
            "source": [
                "### Viewing Checkpoint History\n",
                "\n",
                "Let's explore the checkpoint history to see how the agent's state evolved during execution.  Checkpoints are listed in reverse chronological order (most recent appear first)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2232c2b-154d-4b50-93b0-925eb88e67c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "for checkpoint in graph.get_state_history(config):\n",
                "    print(\n",
                "        f\"(Checkpoint ID: {checkpoint.config['configurable']['checkpoint_id']}) # of messages in state: {len(checkpoint.values.get('messages'))}\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ab07194f-49b4-4fb9-a74b-d86b970cace6",
            "metadata": {},
            "source": [
                "### Testing Memory Persistence\n",
                "\n",
                "Now let's test the power of our checkpointer by continuing the conversation. The agent should remember our previous calculations:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b7117c6a-d1d5-4866-aee9-2b7229fd73fd",
            "metadata": {},
            "outputs": [],
            "source": [
                "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What were the first calculations I asked you to do?\"}]}\n",
                "\n",
                "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
                "    print(chunk)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc602c5b-e6b3-4099-820a-a82266039849",
            "metadata": {},
            "source": [
                "### Starting a New Session\n",
                "\n",
                "Let's demonstrate session isolation by creating a new conversation thread. The agent won't remember the previous calculations in this new session:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8ce88359-ee1e-44bd-9095-ad22b880dda8",
            "metadata": {},
            "outputs": [],
            "source": [
                "config = {\n",
                "    \"configurable\": {\n",
                "        \"thread_id\": \"session-2\", # New session ID\n",
                "        \"actor_id\": \"react-agent-1\", # Same Actor ID\n",
                "    }\n",
                "}\n",
                "\n",
                "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What values did I ask you to multiply and add?\"}]}\n",
                "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
                "    print(chunk)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6fa7bd51-0ece-47d6-aae3-2a9041d98645",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "In this notebook, we've demonstrated:\n",
                "\n",
                "1. How to create an AgentCore Memory resource for checkpointing\n",
                "2. Building a LangGraph agent with automatic state persistence\n",
                "3. Implementing mathematical tools for multi-step calculations\n",
                "4. Using the AgentCoreMemorySaver as a checkpointer backend\n",
                "5. Testing memory persistence and session isolation\n",
                "\n",
                "This integration showcases the power of combining LangGraph's structured workflows with AgentCore Memory's robust checkpointing capabilities to create stateful, persistent AI agents that can maintain context across multiple interactions.\n",
                "\n",
                "The approach we've demonstrated can be extended to more complex use cases, including multi-agent systems, long-running workflows, and specialized state management based on conversation context."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c79d2b47",
            "metadata": {},
            "source": [
                "### Clean up\n",
                "Let's delete the memory to clean up the resources used in this notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c0f9971a",
            "metadata": {},
            "outputs": [],
            "source": [
                "#client.delete_memory_and_wait(memory_id = memory_id, max_wait = 300, poll_interval =10)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
